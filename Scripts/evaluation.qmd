---
title: "Evaluation and Confusion Matrix"
format: html
---

## Evaluation

```{python}
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Evaluate models
models = {
    "Logistic Regression": lr_grid.best_estimator_,
    # add rf_grid.best_estimator_ and dt_grid.best_estimator_ if used
}

for name, model in models.items():
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average="macro")
    print(f"{name} Accuracy: {acc:.4f}")
    print(f"{name} F1 Score: {f1:.4f}")
    ConfusionMatrixDisplay.from_predictions(y_test, y_pred)
    plt.title(name)
    plt.tight_layout()
    plt.show()
```